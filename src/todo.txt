- consider changing how it works
    - have user click in the area of the objects to track
    - have OpenCV find the boundaries of the objects
    - keep the existing code for dense optical flow,
        but only pay attention to the values for the pixels in the object boundary
    - take convex hull of blob to determine where to put text
- issues w/ getting correct contour to follow, b/c thesholding the original image
  emphasizes the shadows instead of the objects

- thinking about using color segmentation
    - segment into colors (using posterizing) & get each individual color (using unique)
    - for each color, get mask in image & get contours from mask
    - then use same containing-contour code to figure out which contour contains click point
- troubleshooting
    - maybe instead of posterizing across all values, don't posterize in the value channel?
    - maybe just hue, even
- issue: posterizing doesn't split into regions very well (perhaps could be refined)

- or instead, have user draw a box around the object. and use average flow across the entire box instead
    - means no need for finding boundaries of object from color segmentation or contouring

- unclear if should take average flow or max flow
    - average does not work at all for hand example
    - max works kinda but gets derailed easily right now


- notes that were in the code before
	'''
	posterize blobs and get individual contours for them
	get all contours in blob image as in OR system
	store user click point(s)
	test against all contours w/ pointPolygonTest to figure out which one it's in
	draw in selected contour
	return selected contour/list of selected contours?

	posterize?
	or just split up by color using inRange as in clownfish example
	then need the unique colors to split up by

	or instead just get the color of the blob at the click location,
	and get a mask for that color, and do contours on that instead,
	to get the contour of the specific blob
	'''

- AAAAAAAAAAAAAAAAAAAA
- getting from selected blob outline to text generation
    - width of text from width of blob; height proportionately scaled
    - get furthest point of outline on edge opposite direction of motion
    - accumulate its optical flow until it has moved far enough that words fit
        - draw word
    - repeat until edge moves out of frame?

- handle multiple contours

- planning out what we want to accomplish yet again
- track the motion of a particular object
- when object moves far enough to fit one instance of text,
    draw it in
- repeat until object is out frame or video ends
- questions:
    - how generalizable do we want it to be?
    - aaaaa
    - how to detect/track particular object

- for inserting text:
    - get direction of movement from optical flow vector
    - calculate this angle every frame
    - anchor text so the top of it is facing the direction of the vector
    - have a set width and height for the text, and measure the width and height of the blob to see if it can fit
    - put as much text as can fit (maybe convert the text to an image or use an image to start with?)
    - crop the text where necessary (numpy slicing? Region Of Interest?)
        - alternatively, only insert the letters of the word that can fit
            - this is hard because letters have different thicknesses
        - alternatively, just shrink down the text so that it can fit
